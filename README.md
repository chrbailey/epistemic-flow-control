<p align="center">
  <h1 align="center">ğŸ’§ Epistemic Flow Control</h1>
  <p align="center">
    <strong>Human-gated probabilistic intelligence for high-stakes domains</strong>
  </p>
  <p align="center">
    <a href="https://github.com/chrbailey/epistemic-flow-control/actions"><img src="https://github.com/chrbailey/epistemic-flow-control/workflows/CI/badge.svg" alt="CI Status"></a>
    <a href="https://github.com/chrbailey/epistemic-flow-control/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg" alt="License"></a>
    <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+"></a>
    <a href="https://github.com/chrbailey/epistemic-flow-control/stargazers"><img src="https://img.shields.io/github/stars/chrbailey/epistemic-flow-control?style=social" alt="Stars"></a>
  </p>
</p>

<p align="center">
  <em>Make LLM outputs reliable for decisions that actually matter.</em>
</p>

---

## ğŸŒŠ The Problem

LLMs are **probabilistically reliable** but not **deterministically correct**. For casual use, that's fine. For high-stakes decisionsâ€”legal, medical, financialâ€”it's dangerous.

Traditional approaches try to make LLMs "more accurate." But they can never reach 100%. **We need a different approach.**

## ğŸ’¡ The Solution: Water in Sand

```
LLM Output (Water) â†’ Human Gates (Channels) â†’ Production (Destination)
```

- **ğŸ’§ LLMs produce "water"** â€” Probabilistic output that flows abundantly
- **ğŸ–ï¸ Domain structure is "sand"** â€” Events, patterns, databases that shape the flow
- **ğŸšª Humans control the gates** â€” Opening, closing, and adjusting channels

**The human doesn't create the water. The human controls where it flows.**

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| **ğŸ“Š Bayesian Pattern Weights** | Confidence grows with evidence using proper statistical updating |
| **â³ Temporal Decay** | Old patterns fade without fresh confirming evidence |
| **ğŸšï¸ Calibrated Confidence** | When we say 80%, we're right 80% of the time |
| **ğŸšª Human Review Gates** | High-stakes decisions require human approval |
| **ğŸ“ˆ Outcome Learning** | Every outcome improves future predictions |
| **ğŸ”¬ Wilson Score Intervals** | Proper uncertainty for small samples |

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/chrbailey/epistemic-flow-control.git
cd epistemic-flow-control

# Install core (no dependencies!)
pip install -e .

# Or with all features
pip install -e ".[all]"
```

### Try the Interactive Demo

```bash
# Install demo dependencies
pip install -e ".[demo]"

# Run the Streamlit demo
streamlit run streamlit_demo/app.py
```

### Basic Usage

```python
from unified_system import EpistemicFlowControl, SystemConfig
from datetime import datetime

# Initialize
config = SystemConfig(db_dir="./data", domain="judicial")
system = EpistemicFlowControl(config)

# Register an information source
system.register_source(
    source_id="pacer",
    name="PACER",
    source_type="official",
    reliability=0.99
)

# Ingest an event (ground truth)
result = system.ingest_event(
    what="Judge granted summary judgment",
    who=["Judge Smith", "Acme Corp", "Beta Inc"],
    when=datetime.now(),
    where="N.D. Cal",
    source_id="pacer",
    raw_text="Order granting motion for summary judgment..."
)

# Patterns are automatically extracted
print(f"Extracted {len(result['patterns_extracted'])} patterns")

# Make a prediction
prediction = system.make_prediction(
    prediction_type="ruling",
    predicted_value="Motion will be granted",
    context={"case_type": "patent"},
    source_patterns=["pat_001"],
    stakes="high"
)

# Check the gate decision
print(f"Gate: {prediction['gate_decision']}")  # "review" for high stakes
print(f"Confidence: {prediction['calibrated_confidence']:.1%}")

# High-stakes items need human review
if prediction['needs_human_review']:
    items = system.get_items_needing_review()
    # Human reviews and approves...
    system.submit_human_review(
        item_id=prediction['prediction_id'],
        reviewer_id="expert_001",
        decision="approve",
        notes="Consistent with recent pattern"
    )
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EPISTEMIC FLOW CONTROL                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Events (Ground Truth)                                         â”‚
â”‚      â†“                                                          â”‚
â”‚   Pattern Extraction (LLM) â†â”€â”€â”€ Human Validation                â”‚
â”‚      â†“                                                          â”‚
â”‚   Pattern Database (Bayesian) â†â”€â”€â”€ Human Override               â”‚
â”‚      â†“                                                          â”‚
â”‚   Predictions (Calibrated) â†â”€â”€â”€ Calibration Engine              â”‚
â”‚      â†“                                                          â”‚
â”‚   Review Gate (Thresholds) â†â”€â”€â”€ Human Review                    â”‚
â”‚      â†“                                                          â”‚
â”‚   Production Output                                             â”‚
â”‚      â†“                                                          â”‚
â”‚   Outcome Recording â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Training Data                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Statistical Foundation

This isn't just another LLM wrapper. It's built on solid statistical principles:

- **[Wilson Score Intervals](https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval)** â€” Conservative confidence bounds that handle small samples correctly. 3 successes out of 5? That's not 60% confidenceâ€”Wilson lower bound says ~23%.

- **[Bayesian Updating](https://en.wikipedia.org/wiki/Bayesian_inference)** â€” Prior beliefs + observations = posterior beliefs. Patterns strengthen with evidence.

- **[Expected Calibration Error](https://arxiv.org/abs/1706.04599)** â€” The standard metric for prediction calibration. We measure and minimize it.

- **Temporal Decay** â€” Patterns become stale. A judge's behavior 5 years ago may not predict today. Exponential decay with configurable half-life.

## ğŸ“ Project Structure

```
epistemic-flow-control/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ event_store.py      # Ground truth storage (770 lines)
â”‚   â”œâ”€â”€ pattern_extractor.py # LLM pattern extraction (957 lines)
â”‚   â””â”€â”€ pattern_database.py  # Bayesian weights (878 lines)
â”œâ”€â”€ gates/
â”‚   â””â”€â”€ review_gate.py      # Human review flow control (907 lines)
â”œâ”€â”€ validation/
â”‚   â””â”€â”€ calibration_engine.py # Accuracy tracking (771 lines)
â”œâ”€â”€ training/
â”‚   â””â”€â”€ data_generator.py   # Training data collection (914 lines)
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ client.py           # LLM integration hub
â”‚   â””â”€â”€ providers/          # Provider implementations
â”œâ”€â”€ examples/               # Compelling demo datasets
â”œâ”€â”€ streamlit_demo/         # Interactive web demo
â”œâ”€â”€ tests/
â””â”€â”€ unified_system.py       # Main integration layer
```

## ğŸ­ Example: The Changing Judge

One of our demo stories shows why this matters:

**Judge Rodriguez** had a 78% summary judgment grant rate. Then she became Chief Judge.

With new administrative duties, her grant rate dropped to 42%. A system relying on historical data would be **dangerously wrong**.

Epistemic Flow Control:
1. â³ **Temporal decay** reduces confidence in old patterns
2. ğŸ“‰ **Bayesian updating** adjusts weights with new evidence
3. ğŸšª **Review gate** routes uncertain predictions to humans
4. ğŸ“ˆ **Calibration** ensures confidence matches reality

The system doesn't try to be perfect. It **knows when it's uncertain**.

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

```bash
# Development setup
pip install -e ".[dev]"

# Run tests
pytest tests/ -v

# Run linter
ruff check .
```

## ğŸ“š Documentation

- [Training Data Requirements](TRAINING_DATA_REQUIREMENTS.md) â€” How to bootstrap the system
- [Validation Package](VALIDATION_PACKAGE.md) â€” Verification and testing guide
- [LLM Layer Review](LLM_LAYER_REVIEW.md) â€” Technical deep-dive into LLM integration

## ğŸ“œ License

[Apache 2.0](LICENSE) â€” Use it, modify it, build on it.

## â­ Star History

If this project helps you build more reliable AI systems, consider giving it a star!

---

<p align="center">
  <strong>Built for decisions that matter.</strong><br>
  <em>Because "probably right" isn't good enough when stakes are high.</em>
</p>
