<p align="center">
  <h1 align="center">ğŸ’§ Epistemic Flow Control</h1>
  <p align="center">
    <strong>Human-gated probabilistic intelligence for high-stakes domains</strong>
  </p>
  <p align="center">
    <a href="https://github.com/chrbailey/epistemic-flow-control/actions"><img src="https://github.com/chrbailey/epistemic-flow-control/workflows/CI/badge.svg" alt="CI Status"></a>
    <a href="https://github.com/chrbailey/epistemic-flow-control/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg" alt="License"></a>
    <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+"></a>
    <a href="https://github.com/chrbailey/epistemic-flow-control/stargazers"><img src="https://img.shields.io/github/stars/chrbailey/epistemic-flow-control?style=social" alt="Stars"></a>
  </p>
</p>

<p align="center">
  <em>Make LLM outputs reliable for decisions that actually matter.</em>
</p>

---

## ğŸŒŠ The Problem

LLMs are **probabilistically reliable** but not **deterministically correct**. For casual use, that's fine. For high-stakes decisionsâ€”legal, medical, financialâ€”it's dangerous.

Traditional approaches try to make LLMs "more accurate." But they can never reach 100%. **We need a different approach.**

## ğŸ’¡ The Solution: Water in Sand

```
LLM Output (Water) â†’ Human Gates (Channels) â†’ Production (Destination)
```

- **ğŸ’§ LLMs produce "water"** â€” Probabilistic output that flows abundantly
- **ğŸ–ï¸ Domain structure is "sand"** â€” Events, patterns, databases that shape the flow
- **ğŸšª Humans control the gates** â€” Opening, closing, and adjusting channels

**The human doesn't create the water. The human controls where it flows.**

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| **ğŸ“Š Bayesian Pattern Weights** | Confidence grows with evidence using proper statistical updating |
| **â³ Temporal Decay** | Old patterns fade without fresh confirming evidence |
| **ğŸšï¸ Calibrated Confidence** | When we say 80%, we're right 80% of the time |
| **ğŸšª Human Review Gates** | High-stakes decisions require human approval |
| **ğŸ“ˆ Outcome Learning** | Every outcome improves future predictions |
| **ğŸ”¬ Wilson Score Intervals** | Proper uncertainty for small samples |

### ğŸ†• New Features (v2.0)

| Feature | Description |
|---------|-------------|
| **ğŸ” Entity Normalization** | Clean messy court data (judge names from URLs, lawyer validation) |
| **âš ï¸ SPOF Detection** | Identify concentration risk using Herfindahl-Hirschman Index |
| **ğŸ“‰ Pattern Drift Detection** | Monitor changes in judicial behavior with 64-dimensional embeddings |
| **âš–ï¸ Jurisdictional Context** | Court-specific and judge-specific guidance (N.D. Cal, Judge Alsup) |

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/chrbailey/epistemic-flow-control.git
cd epistemic-flow-control

# Install core (no dependencies!)
pip install -e .

# Or with all features
pip install -e ".[all]"
```

### Try the Interactive Demo

```bash
# Install demo dependencies
pip install -e ".[demo]"

# Run the Streamlit demo
streamlit run streamlit_demo/app.py
```

### Basic Usage

```python
from unified_system import EpistemicFlowControl, SystemConfig
from datetime import datetime

# Initialize
config = SystemConfig(db_dir="./data", domain="judicial")
system = EpistemicFlowControl(config)

# Register an information source
system.register_source(
    source_id="pacer",
    name="PACER",
    source_type="official",
    reliability=0.99
)

# Ingest an event (ground truth)
result = system.ingest_event(
    what="Judge granted summary judgment",
    who=["Judge Smith", "Acme Corp", "Beta Inc"],
    when=datetime.now(),
    where="N.D. Cal",
    source_id="pacer",
    raw_text="Order granting motion for summary judgment..."
)

# Patterns are automatically extracted
print(f"Extracted {len(result['patterns_extracted'])} patterns")

# Make a prediction
prediction = system.make_prediction(
    prediction_type="ruling",
    predicted_value="Motion will be granted",
    context={"case_type": "patent"},
    source_patterns=["pat_001"],
    stakes="high"
)

# Check the gate decision
print(f"Gate: {prediction['gate_decision']}")  # "review" for high stakes
print(f"Confidence: {prediction['calibrated_confidence']:.1%}")

# High-stakes items need human review
if prediction['needs_human_review']:
    items = system.get_items_needing_review()
    # Human reviews and approves...
    system.submit_human_review(
        item_id=prediction['prediction_id'],
        reviewer_id="expert_001",
        decision="approve",
        notes="Consistent with recent pattern"
    )
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EPISTEMIC FLOW CONTROL                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   Events (Ground Truth)                                         â”‚
â”‚      â†“                                                          â”‚
â”‚   Pattern Extraction (LLM) â†â”€â”€â”€ Human Validation                â”‚
â”‚      â†“                                                          â”‚
â”‚   Pattern Database (Bayesian) â†â”€â”€â”€ Human Override               â”‚
â”‚      â†“                                                          â”‚
â”‚   Predictions (Calibrated) â†â”€â”€â”€ Calibration Engine              â”‚
â”‚      â†“                                                          â”‚
â”‚   Review Gate (Thresholds) â†â”€â”€â”€ Human Review                    â”‚
â”‚      â†“                                                          â”‚
â”‚   Production Output                                             â”‚
â”‚      â†“                                                          â”‚
â”‚   Outcome Recording â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Training Data                  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Statistical Foundation

This isn't just another LLM wrapper. It's built on solid statistical principles:

- **[Wilson Score Intervals](https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval)** â€” Conservative confidence bounds that handle small samples correctly. 3 successes out of 5? That's not 60% confidenceâ€”Wilson lower bound says ~23%.

- **[Bayesian Updating](https://en.wikipedia.org/wiki/Bayesian_inference)** â€” Prior beliefs + observations = posterior beliefs. Patterns strengthen with evidence.

- **[Expected Calibration Error](https://arxiv.org/abs/1706.04599)** â€” The standard metric for prediction calibration. We measure and minimize it.

- **Temporal Decay** â€” Patterns become stale. A judge's behavior 5 years ago may not predict today. Exponential decay with configurable half-life.

## ğŸ“ Project Structure

```
epistemic-flow-control/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ event_store.py       # Ground truth storage
â”‚   â”œâ”€â”€ pattern_extractor.py # LLM pattern extraction
â”‚   â””â”€â”€ pattern_database.py  # Bayesian weights
â”œâ”€â”€ gates/
â”‚   â””â”€â”€ review_gate.py       # Human review flow control
â”œâ”€â”€ validation/
â”‚   â””â”€â”€ calibration_engine.py # Accuracy tracking
â”œâ”€â”€ training/
â”‚   â””â”€â”€ data_generator.py    # Training data collection
â”œâ”€â”€ normalizers/              # ğŸ†• Entity normalization
â”‚   â”œâ”€â”€ judge_normalizer.py  # Clean judge names from URLs
â”‚   â””â”€â”€ lawyer_normalizer.py # Validate lawyer entities
â”œâ”€â”€ concentration/            # ğŸ†• SPOF risk detection
â”‚   â”œâ”€â”€ hhi_calculator.py    # Herfindahl-Hirschman Index
â”‚   â””â”€â”€ spof_detector.py     # Single Point of Failure analysis
â”œâ”€â”€ drift/                    # ğŸ†• Pattern drift detection
â”‚   â”œâ”€â”€ embedding_tracker.py # 64-dimensional pattern embeddings
â”‚   â””â”€â”€ drift_detector.py    # Statistical drift detection
â”œâ”€â”€ jurisdictions/            # ğŸ†• Court-specific context
â”‚   â”œâ”€â”€ base.py              # Abstract jurisdiction classes
â”‚   â”œâ”€â”€ nd_cal.py            # N.D. California rules
â”‚   â””â”€â”€ alsup.py             # Judge Alsup preferences
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ client.py            # LLM integration hub
â”‚   â””â”€â”€ providers/           # Provider implementations
â”œâ”€â”€ examples/                 # Compelling demo datasets
â”œâ”€â”€ streamlit_demo/           # Interactive web demo (9 pages)
â”œâ”€â”€ tests/
â””â”€â”€ unified_system.py         # Main integration layer
```

## ğŸ†• New Feature Examples

### Entity Normalization

```python
from normalizers import JudgeNormalizer, LawyerNormalizer

# Clean messy judge names from various sources
normalizer = JudgeNormalizer()

# From CourtListener URL
result = normalizer.normalize("https://courtlistener.com/person/john-g-roberts-jr/")
print(result.normalized_name)  # "John G. Roberts Jr."

# From PACER format
result = normalizer.normalize("ALSUP, WILLIAM H.")
print(result.normalized_name)  # "William H. Alsup"

# Validate lawyer entities (filter out cities, organizations, pro se)
lawyer_normalizer = LawyerNormalizer()
result = lawyer_normalizer.validate("San Francisco")
print(result.is_valid)  # False - geographic location
```

### Concentration Risk Detection

```python
from concentration import HHICalculator, SPOFDetector

# Calculate market concentration using HHI
calc = HHICalculator()
result = calc.from_counts({
    "Judge Gilstrap": 450,
    "Judge Payne": 180,
    "Judge Schroeder": 150,
    "Others": 220
})
print(f"HHI: {result.hhi}")  # ~2800 (highly concentrated)
print(f"Level: {result.level}")  # concentrated

# Detect Single Point of Failure risks
detector = SPOFDetector()
assessment = detector.analyze(case_counts, entity_type="judge", domain="patent")
if assessment.has_critical_spof:
    print(f"SPOF Alert: {assessment.top_spof.entity_id}")
```

### Pattern Drift Detection

```python
from drift import EmbeddingTracker, DriftDetector

# Track pattern changes over time
tracker = EmbeddingTracker()
detector = DriftDetector()

# Set baseline from historical data
baseline = tracker.generate(
    entity_id="judge_alsup",
    pattern_type="summary_judgment",
    metrics={"grant_rate": 0.45, "avg_days": 120}
)
detector.set_baseline(baseline)

# Check for drift in current pattern
current = tracker.generate(...)
drift_event = detector.detect_drift(current)

if drift_event.requires_recalibration:
    print(f"DRIFT ALERT: {drift_event.severity}")
    print(drift_event.recommendation)
```

### Jurisdictional Context

```python
from unified_system import EpistemicFlowControl, SystemConfig

# Configure for a specific judge
config = SystemConfig(
    domain="judicial",
    jurisdiction="nd_cal",
    judge="alsup"
)
system = EpistemicFlowControl(config)

# Get format requirements
requirements = system.get_format_requirements()
# Returns: 14pt Times New Roman, 25-page limit, etc.

# Get procedural rules for a motion type
rules = system.get_procedural_rules("summary_judgment")
```

## ğŸ­ Example: The Changing Judge

One of our demo stories shows why this matters:

**Judge Rodriguez** had a 78% summary judgment grant rate. Then she became Chief Judge.

With new administrative duties, her grant rate dropped to 42%. A system relying on historical data would be **dangerously wrong**.

Epistemic Flow Control:
1. â³ **Temporal decay** reduces confidence in old patterns
2. ğŸ“‰ **Bayesian updating** adjusts weights with new evidence
3. ğŸšª **Review gate** routes uncertain predictions to humans
4. ğŸ“ˆ **Calibration** ensures confidence matches reality

The system doesn't try to be perfect. It **knows when it's uncertain**.

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

```bash
# Development setup
pip install -e ".[dev]"

# Run tests
pytest tests/ -v

# Run linter
ruff check .
```

## ğŸ“š Documentation

- [Training Data Requirements](TRAINING_DATA_REQUIREMENTS.md) â€” How to bootstrap the system
- [Validation Package](VALIDATION_PACKAGE.md) â€” Verification and testing guide
- [LLM Layer Review](LLM_LAYER_REVIEW.md) â€” Technical deep-dive into LLM integration

## ğŸ“œ License

[Apache 2.0](LICENSE) â€” Use it, modify it, build on it.

## â­ Star History

If this project helps you build more reliable AI systems, consider giving it a star!

---

<p align="center">
  <strong>Built for decisions that matter.</strong><br>
  <em>Because "probably right" isn't good enough when stakes are high.</em>
</p>
